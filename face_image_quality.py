# Author: Jan Niklas Kolf, 2020
# Demo-implementation of SER-FIQ on ArcFace (InsightFace)

import sys
from os import path as os_path

import keras.backend as K
from keras.models import Model as KerasModel
from keras.layers import Dense, Lambda, Input, Dropout
from keras.layers.normalization import BatchNormalization

import numpy as np
import mxnet as mx
import cv2

from tqdm import tqdm

from sklearn.preprocessing import normalize
from sklearn.metrics.pairwise import euclidean_distances


class InsightFace:
    
    def __init__(self,
                 insightface_path:str = "./insightface/",
                 gpu:int=0, # Which gpu should be used -> gpu id
                 det:int=0, # Mtcnn option, 1= Use R+O, 0=Detect from beginning
                 flip:int=0 # Whether do lr flip aug
                 ):
        """
        Reimplementing Insightface's FaceModel class.
        Now the dropout output and the network output are returned after a forward pass.

        Parameters
        ----------
        insightface_path : str, optional
            The path to the insightface repository. The default is "./insightface/".
        gpu : int, optional
            The GPU to be used by Mxnet. The default is 0.
        det : int, optional
            Mtcnn option, 1= Use R+0, 0= Detect from beginning. The default is 0.
        flip:int=0 # Whether do lr flip aug.

        Returns
        -------
        None.

        """

        sym, arg_params, aux_params = mx.model.load_checkpoint(
                                        f"{insightface_path}models/model", 
                                        0
                                        )
    
        all_layers = sym.get_internals()
        sym_dropout = all_layers['dropout0_output']
        sym_fc1 = all_layers["fc1_output"]
        
        sym_grouped = mx.symbol.Group([sym_dropout, sym_fc1])
    
        self.model = mx.mod.Module(symbol=sym_grouped, context=mx.gpu(gpu), label_names = None)
        self.model.bind(data_shapes=[("data", (1,3,112,112))])
        self.model.set_params(arg_params, aux_params)
        
        self.det_minsize = 50
        self.det_threshold = [0.6,0.7,0.8]
        self.det = det

        mtcnn_path = f"{insightface_path}/deploy/mtcnn-model"
        
        sys.path.append(os_path.realpath(os_path.join(insightface_path, "deploy")))
        sys.path.append(os_path.realpath(f"{insightface_path}src/common/"))
        from mtcnn_detector import MtcnnDetector
        from face_preprocess import preprocess
        
        self.preprocess = preprocess
        
        thrs = self.det_threshold if det==0 else [0.0,0.0,0.2]
        
        self.detector = MtcnnDetector(model_folder=mtcnn_path, 
                                      ctx=mx.gpu(0), 
                                      num_worker=1, 
                                      accurate_landmark = True, 
                                      threshold=thrs
                                      )
        

    def get_input(self, face_img):
        """
        Applies preprocessing to the given face image.

        Parameters
        ----------
        face_img : Numpy ndarray
            The face image.

        Returns
        -------
        numpy ndarray of the face image.

        """
        detected = self.detector.detect_face(face_img, det_type=self.det)
        
        if detected is None:
            return None
        
        bbox, points = detected
        
        if bbox.shape[0] == 0:
            return None
        
        points = points[0, :].reshape((2,5)).T
        
        nimg = self.preprocess(face_img, bbox, points, image_size="112,112")
        nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2RGB)
        
        return np.transpose(nimg, (2,0,1))
      
        
    def get_feature(self, aligned_img):
        """
        Runs the given aligned image on the Mxnet Insightface NN.
        Returns the embedding and the dropout0 layer output.

        Parameters
        ----------
        aligned_img : numpy ndarray
            The aligned image returned by get_input
            (or own alignment method).

        Returns
        -------
        embedding : numpy ndarray, (512,)
            The arcface embedding of the image.
        dropout : numpy ndarray (1, 512, 7, 7)
            The output of the dropout0 layer as numpy array.

        """
        input_blob = np.expand_dims(aligned_img, axis=0)
        data = mx.nd.array(input_blob)
        db = mx.io.DataBatch(data=(data,))
        self.model.forward(db, is_train=False)
        dropout, embedding = self.model.get_outputs()

        embedding = normalize(embedding.asnumpy()).flatten()
        
        return embedding, dropout.asnumpy()
        
    
class SERFIQ:
    
    def __init__(self, data_path: str="./data/"):
        """
        Implementing the same-model type model of

        SER-FIQ: Unsupervised Estimation of Face Image Quality 
        Based on Stochastic Embedding Robustness
        
        Philipp Terh√∂rst, Jan Niklas Kolf, Naser Damer, 
        Florian Kirchbuchner, Arjan Kuijper
        
        Accepted at CVPR 2020
        
        Preprint available at https://arxiv.org/abs/2003.09373
        
        Parameters
        ----------
        data_path : str, optional
            Path to the data folder where
            layer weights/bias are located. The default is "./data/".

        
        """
        weights = np.transpose(np.load(
                                f"{data_path}/pre_fc1_weights.npy"
                                       ))
        
        bias = np.load(f"{data_path}/pre_fc1_bias.npy")
        
        def euclid_normalize(x):
            return K.l2_normalize(x, axis=1)

        inputs = Input(shape=(25088,))
        x = inputs
        x = Dropout(0.5)(x, training=True)
        x = Dense(512, name="dense", activation="linear")(x)
        x = BatchNormalization()(x)
        x = Lambda(euclid_normalize)(x)
        output = x
    
        self.model = KerasModel(inputs, outputs=output)
    
        self.model.get_layer("dense").set_weights([weights, bias])
        
    
    def __call__(self, X):
        return self.predict(X)
    
    def predict(self, X):
        return self.model.predict(X)
    

def get_embedding_quality(img_input, 
                        insightface_model : InsightFace, 
                        ser_fiq : SERFIQ, 
                        T:int =100, 
                        use_preprocessing: bool =True,
                        disable_tqdm: bool = False):
    """
    Calculates the SER-FIQ Quality Score for a given img using
    given insightface model and ser-fiq model.
    
    Parameters
    ----------
    img_input : numpy array shape (x,y,3)
        The image to be processed.
    insightface_model : InsightFace
        Instance of InsightFace class
    ser_fiq : SERFIQ
        Instance of SERFIQ class
    T: int, default is 100
        The amount of forward passes the SER-FIQ model should do
    use_preprocessing: bool, default is True
        True: Preprocessing of insightface model is applied (recommended)
        False: No preprocessing is used, needs an already aligned image
    disable_tqdm: bool, default is False
        If True, no tqdm progress bar is displayed

    Returns
    -------
    Arcface/Insightface embedding: numpy array, shape (512,)
    Robustness score : float


    """
    # Apply preprocessing if image is not already aligned
    if use_preprocessing:
        img_input = insightface_model.get_input(img_input)
    
    if img_input is None:
        # No face etc. could be found, no score could be calculated
        return -1.0, -1.0
     
    # Array + prediction with insightface
    dropout_emb = np.empty((1, 25088), dtype=float)
    
    embedding, dropout = insightface_model.get_feature(img_input)
    
    dropout_emb[0] = dropout.flatten()
    
    del dropout

    # Apply T forward passes using keras
    X = np.empty((T, 512), dtype=float)
    for forward_pass in tqdm(range(T),
                             desc="Forward pass",
                             unit="pass",
                             disable=disable_tqdm):

        X[forward_pass] = ser_fiq.predict(dropout_emb)

    norm = normalize(X, axis=1)

    # Only get the upper triangle of the distance matrix
    eucl_dist = euclidean_distances(norm, norm)[np.triu_indices(T, k=1)]

    # Calculate score as given in the paper
    return embedding, 2*(1/(1+np.exp(np.mean(eucl_dist))))
    

def get_arcface_embedding(img_input, use_preprocessing: bool = True):
    """
    Calculate the Arcface/Insightface Embedding of the given image.
    Applies preprocessing if set so.

    Parameters
    ----------
    img_input : numpy ndarray
        Face image.
    use_preprocessing : bool, optional
        If True, preprocessing with Mtcnn is applied. The default is True.

    Returns
    -------
    numpy ndarray (512,)
        The arcface embedding.

    """
    # Apply preprocessing if image is not already aligned
    if use_preprocessing:
        img_input = insightface_model.get_input(img_input)
    
    if img_input is None:
        # No face etc. could be found, no score could be calculated
        return -1.0
    
    embedding, dropout = insightface_model.get_feature(img_input)
    
    return embedding
